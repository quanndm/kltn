{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9c5f890",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanndm/kltn/blob/dev/notebooks/tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f019e008",
      "metadata": {
        "id": "f019e008"
      },
      "source": [
        "## Init - import library - download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "49327657",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49327657",
        "outputId": "a413be38-e206-4fa1-f893-5e3733f41c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'kltn'...\n",
            "remote: Enumerating objects: 1224, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 1224 (delta 3), reused 8 (delta 2), pack-reused 1212 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1224/1224), 13.28 MiB | 14.16 MiB/s, done.\n",
            "Resolving deltas: 100% (791/791), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf kltn\n",
        "!rm -rf sample_data\n",
        "!git clone -b dev https://github.com/quanndm/kltn.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b160b91e",
      "metadata": {
        "id": "b160b91e"
      },
      "outputs": [],
      "source": [
        "from kltn.init.install_dependencies import install_packages, load_config\n",
        "install_packages(\"./kltn\")\n",
        "config = load_config(\"./kltn/parameters.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4fd33572",
      "metadata": {
        "id": "4fd33572"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "from kltn import *\n",
        "from kltn.datasets.get_datasets import get_datasets_stage2\n",
        "from kltn.utils.logger import init_logger\n",
        "from kltn.utils.train_val_epochs import trainer, trainer_stage2\n",
        "from kltn.utils.metrics import  DiceMetric, TverskyLossWSigmoid\n",
        "from kltn.models.model_factory import ModelFactory\n",
        "from kltn.utils.visualize_results import visualize_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b1fce3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1fce3c",
        "outputId": "297dc15c-dc3a-4380-b254-6068d3428b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1af26197",
      "metadata": {
        "id": "1af26197"
      },
      "outputs": [],
      "source": [
        "LOGGER = init_logger(config[\"log_path\"])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "651a9bd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "651a9bd1",
        "outputId": "4fa11670-6528-4c96-f106-624a866083b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00% complete (down: 0.0 kB/s up: 0.0 kB/s peers: 1) downloading LITS17 (https://academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (1)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (1)\n",
            "LITS17 (https://academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (1)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (1)\n",
            "LITS17 (udp://tracker.opentrackr.org:1337/announce)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (1)\n",
            "2.12% complete (down: 31139.7 kB/s up: 928.0 kB/s peers: 10) downloading LITS17 (https://academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (2)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (2)\n",
            "LITS17 (https://academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (2)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (2)\n",
            "23.32% complete (down: 50400.7 kB/s up: 1471.9 kB/s peers: 10) downloading LITS17 (https://academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (3)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (3)\n",
            "LITS17 (udp://tracker.opentrackr.org:1337/announce)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (2)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (3)\n",
            "LITS17 (https://academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (3)\n",
            "49.16% complete (down: 59612.3 kB/s up: 1746.2 kB/s peers: 9) downloading could not map port using UPnP[172.28.0.12]: no router found\n",
            "could not map port using UPnP[172.28.0.12]: no router found\n",
            "60.57% complete (down: 52231.6 kB/s up: 1535.0 kB/s peers: 10) downloading LITS17 (https://academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (4)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (4)\n",
            "LITS17 (udp://tracker.opentrackr.org:1337/announce)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (3)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (4)\n",
            "LITS17 (https://academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (4)\n",
            "100.00% complete (down: 9834.5 kB/s up: 284.9 kB/s peers: 0) seeding LITS17 (https://academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (5)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (5)\n",
            "LITS17 (udp://tracker.opentrackr.org:1337/announce)[127.0.0.1:6881] v1 skipping tracker announce (unreachable) \"\" (4)\n",
            "LITS17 (https://academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (5)\n",
            "LITS17 (https://ipv6.academictorrents.com/announce.php)[172.28.0.12:6881] v1 unspecified system error \"\" (5)\n",
            "LITS17 complete\n",
            "\n",
            "Unzipping files in /content/LITS17\n",
            "Unzipping complete\n"
          ]
        }
      ],
      "source": [
        "from kltn.datasets.prepare_data import prepare_dataset_LiTS\n",
        "prepare_dataset_LiTS(dir_name=config[\"source_folder_lits\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a5d228",
      "metadata": {
        "id": "a6a5d228"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a001fd01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a001fd01",
        "outputId": "e0e1e0d3-71ca-465c-cce7-6e8af678965a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weight_path = \"/content/drive/MyDrive/KLTN/code/weight/best_metric_model_UNet3DWResNeXtCoT.pth\"\n",
        "model_stage_1 = ModelFactory.get_model(\"unet3d_resnextcot\",in_channels=1, n_classes=3, n_channels=16).to(device)\n",
        "model_stage_1.load_state_dict(torch.load(weight_path, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d205f4c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d205f4c0",
        "outputId": "b991dc51-bdbc-4949-e257-fa05a448f58c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['out.conv.weight', 'out.conv.bias'], unexpected_keys=[])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ModelFactory.get_model(\"unet3d_resnextcot\",in_channels=1, n_classes=1, n_channels=16).to(device)\n",
        "model.load_state_dict({\n",
        "    k: v for k, v in model_stage_1.state_dict().items() if \"out\" not in k\n",
        "}, strict=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce8e3bc",
      "metadata": {
        "id": "3ce8e3bc"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1df07b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1df07b9",
        "outputId": "608daddf-2754-441b-9f5a-1e27129c2100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105 26\n"
          ]
        }
      ],
      "source": [
        "full_train_dataset, val_dataset = get_datasets_stage2(source_folder=config[\"source_folder_lits\"], seed=123, fold_number=2, model_stage_1=model_stage_1)\n",
        "print(len(full_train_dataset), len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b43b5add",
      "metadata": {
        "id": "b43b5add"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(full_train_dataset, batch_size=1, shuffle=True,\n",
        "                                           num_workers=0, pin_memory=True, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False,\n",
        "                                         pin_memory=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d908bf",
      "metadata": {
        "id": "41d908bf"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4d88d064",
      "metadata": {
        "id": "4d88d064"
      },
      "outputs": [],
      "source": [
        "criterion = TverskyLossWSigmoid().to(device)\n",
        "\n",
        "dice_acc = DiceMetric(include_background=False, reduction='mean_batch', get_not_nans=True)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=float(config[\"learning_rate_train\"]), weight_decay=float(config[\"weight_decay\"]))\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(config[\"max_epochs\"]), eta_min = float(config[\"eta_min\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5c9e63dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5c9e63dc",
        "outputId": "21e00ec2-54eb-40aa-a3f0-1c6f9b692f62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TRAINER] Start TRAIN process...\n",
            "INFO:kltn.utils.logger:[TRAINER] Start TRAIN process...\n",
            "\n",
            "==============================Training epoch 1==============================\n",
            "INFO:kltn.utils.logger:\n",
            "==============================Training epoch 1==============================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 1/105 loss: 0.8004 time 3.37s\n",
            "Epoch 1/10 2/105 loss: 0.7922 time 6.62s\n",
            "Epoch 1/10 3/105 loss: 0.7786 time 3.48s\n",
            "Epoch 1/10 4/105 loss: 0.7712 time 5.17s\n",
            "Epoch 1/10 5/105 loss: 0.7732 time 1.77s\n",
            "Epoch 1/10 6/105 loss: 0.7686 time 5.82s\n",
            "Epoch 1/10 7/105 loss: 0.7637 time 1.39s\n",
            "Epoch 1/10 8/105 loss: 0.7617 time 6.27s\n",
            "Epoch 1/10 9/105 loss: 0.7643 time 2.92s\n",
            "Epoch 1/10 10/105 loss: 0.7654 time 6.07s\n",
            "Epoch 1/10 11/105 loss: 0.7659 time 1.84s\n",
            "Epoch 1/10 12/105 loss: 0.7663 time 1.18s\n",
            "Epoch 1/10 13/105 loss: 0.7670 time 6.08s\n",
            "Epoch 1/10 14/105 loss: 0.7679 time 5.82s\n",
            "Epoch 1/10 15/105 loss: 0.7681 time 2.57s\n",
            "Epoch 1/10 16/105 loss: 0.7659 time 9.37s\n",
            "Epoch 1/10 17/105 loss: 0.7663 time 1.39s\n",
            "Epoch 1/10 18/105 loss: 0.7672 time 4.67s\n",
            "Epoch 1/10 19/105 loss: 0.7675 time 2.22s\n",
            "Epoch 1/10 20/105 loss: 0.7674 time 2.55s\n",
            "Epoch 1/10 21/105 loss: 0.7677 time 6.87s\n",
            "Epoch 1/10 22/105 loss: 0.7681 time 4.47s\n",
            "Epoch 1/10 23/105 loss: 0.7684 time 4.60s\n",
            "Epoch 1/10 24/105 loss: 0.7683 time 5.78s\n",
            "Epoch 1/10 25/105 loss: 0.7687 time 5.77s\n",
            "Epoch 1/10 26/105 loss: 0.7689 time 5.56s\n",
            "Epoch 1/10 27/105 loss: 0.7687 time 10.07s\n",
            "Epoch 1/10 28/105 loss: 0.7687 time 1.27s\n",
            "Epoch 1/10 29/105 loss: 0.7685 time 1.68s\n",
            "Epoch 1/10 30/105 loss: 0.7688 time 1.12s\n",
            "Epoch 1/10 31/105 loss: 0.7686 time 2.87s\n",
            "Epoch 1/10 32/105 loss: 0.7686 time 7.91s\n",
            "Epoch 1/10 33/105 loss: 0.7685 time 1.68s\n",
            "Epoch 1/10 34/105 loss: 0.7681 time 1.41s\n",
            "Epoch 1/10 35/105 loss: 0.7680 time 5.62s\n",
            "Epoch 1/10 36/105 loss: 0.7678 time 3.98s\n",
            "Epoch 1/10 37/105 loss: 0.7677 time 1.57s\n",
            "Epoch 1/10 38/105 loss: 0.7676 time 1.77s\n",
            "Epoch 1/10 39/105 loss: 0.7674 time 2.01s\n",
            "Epoch 1/10 40/105 loss: 0.7659 time 5.38s\n",
            "Epoch 1/10 41/105 loss: 0.7657 time 1.72s\n",
            "Epoch 1/10 42/105 loss: 0.7643 time 3.88s\n",
            "Epoch 1/10 43/105 loss: 0.7645 time 4.85s\n",
            "Epoch 1/10 44/105 loss: 0.7632 time 5.79s\n",
            "Epoch 1/10 45/105 loss: 0.7624 time 5.36s\n",
            "Epoch 1/10 46/105 loss: 0.7624 time 5.52s\n",
            "Epoch 1/10 47/105 loss: 0.7618 time 2.39s\n",
            "Epoch 1/10 48/105 loss: 0.7618 time 1.29s\n",
            "Epoch 1/10 49/105 loss: 0.7617 time 1.75s\n",
            "Epoch 1/10 50/105 loss: 0.7606 time 2.71s\n",
            "Epoch 1/10 51/105 loss: 0.7605 time 6.80s\n",
            "Epoch 1/10 52/105 loss: 0.7600 time 2.41s\n",
            "Epoch 1/10 53/105 loss: 0.7600 time 6.89s\n",
            "Epoch 1/10 54/105 loss: 0.7600 time 1.55s\n",
            "Epoch 1/10 55/105 loss: 0.7601 time 4.09s\n",
            "Epoch 1/10 56/105 loss: 0.7602 time 5.39s\n",
            "Epoch 1/10 57/105 loss: 0.7593 time 5.61s\n",
            "Epoch 1/10 58/105 loss: 0.7590 time 5.37s\n",
            "Epoch 1/10 59/105 loss: 0.7590 time 6.76s\n",
            "Epoch 1/10 60/105 loss: 0.7591 time 5.36s\n",
            "Epoch 1/10 61/105 loss: 0.7586 time 5.91s\n",
            "Epoch 1/10 62/105 loss: 0.7584 time 4.71s\n",
            "Epoch 1/10 63/105 loss: 0.7581 time 6.50s\n",
            "Epoch 1/10 64/105 loss: 0.7581 time 3.44s\n",
            "Epoch 1/10 65/105 loss: 0.7581 time 5.24s\n",
            "Epoch 1/10 66/105 loss: 0.7581 time 4.68s\n",
            "Epoch 1/10 67/105 loss: 0.7572 time 6.72s\n",
            "Epoch 1/10 68/105 loss: 0.7572 time 4.98s\n",
            "Epoch 1/10 69/105 loss: 0.7571 time 3.88s\n",
            "Epoch 1/10 70/105 loss: 0.7570 time 1.78s\n",
            "Epoch 1/10 71/105 loss: 0.7566 time 7.02s\n",
            "Epoch 1/10 72/105 loss: 0.7566 time 5.20s\n",
            "Epoch 1/10 73/105 loss: 0.7566 time 4.63s\n",
            "Epoch 1/10 74/105 loss: 0.7566 time 2.72s\n",
            "Epoch 1/10 75/105 loss: 0.7566 time 1.28s\n",
            "Epoch 1/10 76/105 loss: 0.7565 time 2.29s\n",
            "Epoch 1/10 77/105 loss: 0.7564 time 4.44s\n",
            "Epoch 1/10 78/105 loss: 0.7564 time 3.14s\n",
            "Epoch 1/10 79/105 loss: 0.7562 time 3.57s\n",
            "Epoch 1/10 80/105 loss: 0.7561 time 3.59s\n",
            "Epoch 1/10 81/105 loss: 0.7558 time 1.33s\n",
            "Epoch 1/10 82/105 loss: 0.7552 time 6.19s\n",
            "Epoch 1/10 83/105 loss: 0.7549 time 1.41s\n",
            "Epoch 1/10 84/105 loss: 0.7547 time 2.85s\n",
            "Epoch 1/10 85/105 loss: 0.7546 time 4.68s\n",
            "Epoch 1/10 86/105 loss: 0.7546 time 4.31s\n",
            "Epoch 1/10 87/105 loss: 0.7545 time 6.87s\n",
            "Epoch 1/10 88/105 loss: 0.7544 time 3.88s\n",
            "Epoch 1/10 89/105 loss: 0.7544 time 1.03s\n",
            "Epoch 1/10 90/105 loss: 0.7544 time 6.48s\n",
            "Epoch 1/10 91/105 loss: 0.7540 time 2.54s\n",
            "Epoch 1/10 92/105 loss: 0.7539 time 4.48s\n",
            "Epoch 1/10 93/105 loss: 0.7539 time 7.05s\n",
            "Epoch 1/10 94/105 loss: 0.7537 time 4.79s\n",
            "Epoch 1/10 95/105 loss: 0.7537 time 6.31s\n",
            "Epoch 1/10 96/105 loss: 0.7536 time 6.67s\n",
            "Epoch 1/10 97/105 loss: 0.7535 time 3.32s\n",
            "Epoch 1/10 98/105 loss: 0.7534 time 1.00s\n",
            "Epoch 1/10 99/105 loss: 0.7529 time 1.87s\n",
            "Epoch 1/10 100/105 loss: 0.7528 time 1.97s\n",
            "Epoch 1/10 101/105 loss: 0.7527 time 5.21s\n",
            "Epoch 1/10 102/105 loss: 0.7526 time 1.85s\n",
            "Epoch 1/10 103/105 loss: 0.7525 time 5.30s\n",
            "Epoch 1/10 104/105 loss: 0.7524 time 0.91s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Final training epochs: 1/10 ---[loss: 0.7523] ---[time 431.36s]\n",
            "INFO:kltn.utils.logger:Final training epochs: 1/10 ---[loss: 0.7523] ---[time 431.36s]\n",
            "\n",
            "********************Epoch 1 Validation********************\n",
            "INFO:kltn.utils.logger:\n",
            "********************Epoch 1 Validation********************\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 105/105 loss: 0.7523 time 5.86s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/kltn/utils/metrics.py:151: RuntimeWarning: invalid value encountered in divide\n",
            "  self.avg = self.sum / self.count\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-74f0b97347d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrecalls_tumor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtime_tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_stage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/kltn/utils/train_val_epochs.py\u001b[0m in \u001b[0;36mtrainer_stage2\u001b[0;34m(model, train_loader, val_loader, optimizer, loss_func, acc_func, scheduler, batch_size, max_epochs, start_epoch, val_every, logger, path_save_model, save_model, post_fix)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{'*' * 20}Epoch {epoch} Validation{'*' * 20}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mval_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mval_ious\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_precisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_recalls\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mval_dice_tumor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/kltn/utils/train_val_epochs.py\u001b[0m in \u001b[0;36mval_epoch\u001b[0;34m(model, loader, epoch, acc_func, max_epochs, logger)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0miou_liver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mious\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0miou_tumor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mious\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0miou_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "LOGGER.info(\"[TRAINER] Start TRAIN process...\")\n",
        "\n",
        "(\n",
        "    val_acc_max,\n",
        "    best_epoch,\n",
        "    dices_tumor,\n",
        "    loss_epochs,\n",
        "    trains_epoch,\n",
        "    ious_tumor,\n",
        "    precisions_tumor,\n",
        "    recalls_tumor,\n",
        "    time_tmp\n",
        ") = trainer_stage2(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    loss_func=criterion,\n",
        "    acc_func=dice_acc,\n",
        "    scheduler=scheduler,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    max_epochs = 10,\n",
        "    start_epoch = config[\"start_epoch\"],\n",
        "    val_every=config[\"val_every\"],\n",
        "    path_save_model=config[\"path_save_model_state\"],\n",
        "    logger=LOGGER,\n",
        "    save_model=False,\n",
        "    post_fix=\"tumor\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd8638d",
      "metadata": {
        "id": "bcd8638d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "path_save_result = f\"/content/drive/MyDrive/KLTN/code/result_model_{model.__class__.__name__}_tumor.json\"\n",
        "\n",
        "results = {\n",
        "    \"dice_tumor\": [float(x) for x in np.array(dices_tumor, dtype=np.float32)],\n",
        "    \"loss\": [float(x) for x in np.array(loss_epochs, dtype= np.float32)],\n",
        "    \"iou_tumor\": [float(x) for x in np.array(ious_tumor, dtype=np.float32)],\n",
        "    \"precision_tumor\": [float(x) for x in np.array(precisions_tumor, dtype=np.float32)],\n",
        "    \"recall_tumor\": [float(x) for x in np.array(recalls_tumor, dtype=np.float32)],\n",
        "    \"best_epoch\": best_epoch,\n",
        "    \"time_train\": time_tmp\n",
        "}\n",
        "with open(path_save_result, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
